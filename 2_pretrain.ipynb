{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794e4f44-970d-4f30-a0d9-58c5df31b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "from gpt_model import GPTModel\n",
    "from data_loader_v1 import create_dataloader_v1\n",
    "from generate_text import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30d339",
   "metadata": {},
   "source": [
    "### Detect if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16e6d70-0358-4455-b556-01f4283ac928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d281a",
   "metadata": {},
   "source": [
    "### Set up model configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72561797-a3f0-4d84-9883-64c447482389",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.2,       # Dropout rate\n",
    "    \"qkv_bias\": False,      # Query-Key-Value bias\n",
    "    \"device\": device,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fbf11",
   "metadata": {},
   "source": [
    "### Load training and validation data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b562de-efe1-40d2-a5ba-350b1edb7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train_text_data.txt'\n",
    "val_file_path = 'val_text_data.txt'\n",
    "\n",
    "with open(train_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    train_data = file.read()\n",
    "with open(val_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    val_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf608bf",
   "metadata": {},
   "source": [
    "### Initialize data loaders for training\n",
    "Data loaders implementation can be found in `./data_loader_v1.py`.\n",
    "\n",
    "This implementation follows the omplementation detailed in _Raschka, Sebastian. Build a Large Language Model (From Scratch). Manning Publications, 2024_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddf6dae-302d-4fc7-853b-2806a0c7d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=4,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=4,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860e138",
   "metadata": {},
   "source": [
    "### Initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a472b92-340a-46c8-8526-d0ab1a59fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 1820039\n",
      "Tokens: 415577\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(train_data + val_data)\n",
    "total_tokens = len(tokenizer.encode(train_data + val_data, allowed_special={'<|endoftext|>'}))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb273e3a-602f-45b0-a404-89fa88b6aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f969edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def clean(): \n",
    "    \"\"\"\n",
    "    This is a function for GPU data claening before and after training\n",
    "    \"\"\"\n",
    "    \n",
    "    os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "    \n",
    "    gc.collect()  # Force garbage collection\n",
    "    torch.mps.empty_cache()  # Attempt to release MPS memory\n",
    "    \n",
    "    # Move tensors to CPU\n",
    "    for tensor in list(globals().values()):\n",
    "        if isinstance(tensor, torch.Tensor) and tensor.device == torch.device(\"mps\"):\n",
    "            tensor.to(\"cpu\")\n",
    "\n",
    "    # Delete all tensors\n",
    "    del tensor\n",
    "    torch.mps.empty_cache()\n",
    "    gc.collect()  # Force garbage collection\n",
    "    print(\"MPS Available:\", torch.backends.mps.is_available())\n",
    "    print(\"Allocated Memory:\", torch.mps.current_allocated_memory() / (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da82d2c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2c9bfd-5c57-4af6-98e8-5da47988d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_train import train_model_simple\n",
    "import time\n",
    "\n",
    "train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "\n",
    "def train(train_loader, val_loader,\n",
    "          num_epochs=10, eval_iter=5, \n",
    "          sample_text=\"Every effort moves you\",\n",
    "          checkpoint_path=\"model_and_optimizer.pth\"):\n",
    "\n",
    "    global train_losses, val_losses, track_tokens_seen  # Ensure these are updated globally\n",
    "\n",
    "    if device == \"mps\":\n",
    "        clean()\n",
    "        print(50 * \"=\")\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.05)\n",
    "\n",
    "    # Pass train_losses and val_losses as references\n",
    "    train_model_simple(\n",
    "        model, train_loader, val_loader, optimizer,\n",
    "        num_epochs=num_epochs, eval_iter=eval_iter,\n",
    "        start_context=sample_text, cfg=GPT_CONFIG_124M,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        train_losses=train_losses, val_losses=val_losses,\n",
    "        track_tokens_seen=track_tokens_seen\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "    \n",
    "    if device == \"mps\":\n",
    "        print(50 * \"=\")\n",
    "        clean()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ae6fc",
   "metadata": {},
   "source": [
    "### Train the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda45148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Available: True\n",
      "Allocated Memory: 0.0 MB\n",
      "==================================================\n",
      "Starting training...\n",
      "Ep 1 (Step 000000): Train loss 10.521, Val loss 10.502\n",
      "Ep 1 (Step 000025): Train loss 7.593, Val loss 7.567\n",
      "Ep 1 (Step 000050): Train loss 6.531, Val loss 6.613\n",
      "Ep 1 (Step 000075): Train loss 6.171, Val loss 6.316\n",
      "Ep 1 (Step 000100): Train loss 5.955, Val loss 6.079\n",
      "Ep 1 (Step 000125): Train loss 5.765, Val loss 5.947\n",
      "Ep 1 (Step 000150): Train loss 5.593, Val loss 5.798\n",
      "Ep 1 (Step 000175): Train loss 5.504, Val loss 5.699\n",
      "Ep 1 (Step 000200): Train loss 5.366, Val loss 5.609\n",
      "Ep 1 (Step 000225): Train loss 5.361, Val loss 5.547\n",
      "Ep 1 (Step 000250): Train loss 5.231, Val loss 5.508\n",
      "Ep 1 (Step 000275): Train loss 5.203, Val loss 5.447\n",
      "Ep 1 (Step 000300): Train loss 5.135, Val loss 5.394\n",
      "Ep 1 (Step 000325): Train loss 5.125, Val loss 5.357\n",
      "Ep 1 (Step 000350): Train loss 5.033, Val loss 5.329\n",
      "The horses are a way on such a family\n",
      "Ep 2 (Step 000375): Train loss 5.000, Val loss 5.297\n",
      "Ep 2 (Step 000400): Train loss 4.942, Val loss 5.271\n",
      "Ep 2 (Step 000425): Train loss 4.892, Val loss 5.245\n",
      "Ep 2 (Step 000450): Train loss 4.872, Val loss 5.209\n",
      "Ep 2 (Step 000475): Train loss 4.873, Val loss 5.207\n",
      "Ep 2 (Step 000500): Train loss 4.787, Val loss 5.187\n",
      "Ep 2 (Step 000525): Train loss 4.773, Val loss 5.171\n",
      "Ep 2 (Step 000550): Train loss 4.800, Val loss 5.139\n",
      "Ep 2 (Step 000575): Train loss 4.724, Val loss 5.135\n",
      "Ep 2 (Step 000600): Train loss 4.719, Val loss 5.124\n",
      "Ep 2 (Step 000625): Train loss 4.660, Val loss 5.098\n",
      "Ep 2 (Step 000650): Train loss 4.663, Val loss 5.085\n",
      "Ep 2 (Step 000675): Train loss 4.604, Val loss 5.088\n",
      "Ep 2 (Step 000700): Train loss 4.653, Val loss 5.051\n",
      "Ep 2 (Step 000725): Train loss 4.564, Val loss 5.049\n",
      "The horses are, I must be done for it would the most people so happy to be no one of the very good good in the time\n",
      "Ep 3 (Step 000750): Train loss 4.590, Val loss 5.039\n",
      "Ep 3 (Step 000775): Train loss 4.492, Val loss 5.040\n",
      "Ep 3 (Step 000800): Train loss 4.569, Val loss 5.022\n",
      "Ep 3 (Step 000825): Train loss 4.565, Val loss 5.019\n",
      "Ep 3 (Step 000850): Train loss 4.469, Val loss 4.998\n",
      "Ep 3 (Step 000875): Train loss 4.520, Val loss 4.987\n",
      "Ep 3 (Step 000900): Train loss 4.471, Val loss 4.978\n",
      "Ep 3 (Step 000925): Train loss 4.454, Val loss 4.962\n",
      "Ep 3 (Step 000950): Train loss 4.431, Val loss 4.974\n",
      "Ep 3 (Step 000975): Train loss 4.419, Val loss 4.967\n",
      "Ep 3 (Step 001000): Train loss 4.416, Val loss 4.949\n",
      "Ep 3 (Step 001025): Train loss 4.426, Val loss 4.939\n",
      "Ep 3 (Step 001050): Train loss 4.363, Val loss 4.925\n",
      "Ep 3 (Step 001075): Train loss 4.296, Val loss 4.918\n",
      "The horses are quite on one or in the other, a few minutes were to the other point of course of her brother, which had no other\n",
      "Ep 4 (Step 001100): Train loss 4.329, Val loss 4.912\n",
      "Ep 4 (Step 001125): Train loss 4.314, Val loss 4.918\n",
      "Ep 4 (Step 001150): Train loss 4.278, Val loss 4.903\n",
      "Ep 4 (Step 001175): Train loss 4.349, Val loss 4.912\n",
      "Ep 4 (Step 001200): Train loss 4.298, Val loss 4.900\n",
      "Ep 4 (Step 001225): Train loss 4.330, Val loss 4.907\n",
      "Ep 4 (Step 001250): Train loss 4.264, Val loss 4.889\n",
      "Ep 4 (Step 001275): Train loss 4.205, Val loss 4.884\n",
      "Ep 4 (Step 001300): Train loss 4.223, Val loss 4.882\n",
      "Ep 4 (Step 001325): Train loss 4.146, Val loss 4.871\n",
      "Ep 4 (Step 001350): Train loss 4.219, Val loss 4.872\n",
      "Ep 4 (Step 001375): Train loss 4.200, Val loss 4.855\n",
      "Ep 4 (Step 001400): Train loss 4.211, Val loss 4.860\n",
      "Ep 4 (Step 001425): Train loss 4.127, Val loss 4.852\n",
      "Ep 4 (Step 001450): Train loss 4.191, Val loss 4.842\n",
      "The horses are engaged to her the whole of her mother, and this, and with some very well with him\n",
      "Ep 5 (Step 001475): Train loss 4.072, Val loss 4.851\n",
      "Ep 5 (Step 001500): Train loss 4.104, Val loss 4.849\n",
      "Ep 5 (Step 001525): Train loss 4.063, Val loss 4.852\n",
      "Ep 5 (Step 001550): Train loss 4.103, Val loss 4.851\n",
      "Ep 5 (Step 001575): Train loss 4.080, Val loss 4.853\n",
      "Ep 5 (Step 001600): Train loss 4.025, Val loss 4.837\n",
      "Ep 5 (Step 001625): Train loss 3.986, Val loss 4.830\n",
      "Ep 5 (Step 001650): Train loss 3.990, Val loss 4.826\n",
      "Ep 5 (Step 001675): Train loss 4.000, Val loss 4.826\n",
      "Ep 5 (Step 001700): Train loss 3.993, Val loss 4.815\n",
      "Ep 5 (Step 001725): Train loss 4.008, Val loss 4.816\n",
      "Ep 5 (Step 001750): Train loss 3.960, Val loss 4.815\n",
      "Ep 5 (Step 001775): Train loss 3.974, Val loss 4.816\n",
      "Ep 5 (Step 001800): Train loss 3.902, Val loss 4.810\n",
      "The horses are full of his mind\n",
      "Ep 6 (Step 001825): Train loss 3.923, Val loss 4.792\n",
      "Ep 6 (Step 001850): Train loss 3.918, Val loss 4.797\n",
      "Ep 6 (Step 001875): Train loss 3.897, Val loss 4.815\n",
      "Ep 6 (Step 001900): Train loss 3.914, Val loss 4.804\n",
      "Ep 6 (Step 001925): Train loss 3.830, Val loss 4.806\n",
      "Ep 6 (Step 001950): Train loss 3.878, Val loss 4.792\n",
      "Ep 6 (Step 001975): Train loss 3.879, Val loss 4.789\n",
      "Ep 6 (Step 002000): Train loss 3.795, Val loss 4.792\n",
      "Ep 6 (Step 002025): Train loss 3.835, Val loss 4.815\n",
      "Ep 6 (Step 002050): Train loss 3.786, Val loss 4.810\n",
      "Ep 6 (Step 002075): Train loss 3.753, Val loss 4.797\n",
      "Ep 6 (Step 002100): Train loss 3.756, Val loss 4.798\n",
      "Ep 6 (Step 002125): Train loss 3.753, Val loss 4.787\n",
      "Ep 6 (Step 002150): Train loss 3.728, Val loss 4.786\n",
      "Ep 6 (Step 002175): Train loss 3.726, Val loss 4.786\n",
      "The horses are not so; and if he walked on his wife\n",
      "Ep 7 (Step 002200): Train loss 3.727, Val loss 4.796\n",
      "Ep 7 (Step 002225): Train loss 3.677, Val loss 4.788\n",
      "Ep 7 (Step 002250): Train loss 3.667, Val loss 4.819\n",
      "Ep 7 (Step 002275): Train loss 3.647, Val loss 4.807\n",
      "Ep 7 (Step 002300): Train loss 3.584, Val loss 4.807\n",
      "Ep 7 (Step 002325): Train loss 3.592, Val loss 4.808\n",
      "Ep 7 (Step 002350): Train loss 3.620, Val loss 4.801\n",
      "Ep 7 (Step 002375): Train loss 3.603, Val loss 4.802\n",
      "Ep 7 (Step 002400): Train loss 3.579, Val loss 4.791\n",
      "Ep 7 (Step 002425): Train loss 3.537, Val loss 4.802\n",
      "Ep 7 (Step 002450): Train loss 3.500, Val loss 4.800\n",
      "Ep 7 (Step 002475): Train loss 3.536, Val loss 4.782\n",
      "Ep 7 (Step 002500): Train loss 3.498, Val loss 4.791\n",
      "Ep 7 (Step 002525): Train loss 3.485, Val loss 4.785\n",
      "Ep 7 (Step 002550): Train loss 3.489, Val loss 4.799\n",
      "The horses are going to be kept them on board\n",
      "Training completed in 46.72 minutes.\n",
      "==================================================\n",
      "MPS Available: True\n",
      "Allocated Memory: 2943.4462890625 MB\n"
     ]
    }
   ],
   "source": [
    "# train model on 3 books\n",
    "\n",
    "train(train_loader, val_loader, num_epochs=7,\n",
    "      eval_iter=25, sample_text=\"The horses are\",\n",
    "      checkpoint_path=\"model_and_optimizer_5.pth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c4e59",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6651aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(\"cpu\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer_5.pth\", weights_only=True)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adb0c982",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss Bennet has inherited the estate from her aunt, so she must suffer by her father to her own family.\n",
      "\"I am afraid it. Yes, dear aunt, I shall find you, and make it. You will not be very different great a very ill-in-morrow; and you know my word\n",
      "==================================================\n",
      "Mr. Darcy has inherited the estate from his aunt, so he must be a very good deal more anxious to her; for she could not know, and it could not be his return, and she might not help feeling.\n",
      "\"I am sure I am not know, or the next morning to his conduct of him\n"
     ]
    }
   ],
   "source": [
    "from generate_text import generate\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "text = generate(\n",
    "    model=model, prompt=\"Miss Bennet has inherited the estate from her aunt, so she must\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)\n",
    "    \n",
    "print(50*\"=\")\n",
    "    \n",
    "text = generate(\n",
    "    model=model, prompt=\"Mr. Darcy has inherited the estate from his aunt, so he must\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81220f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss Bennet has inherited the estate from her aunt, so she must have been very early to a few hours, and she knew how happy.\n",
      "The evening was going to the former friends, and in the ladies of this time, she had the entrance of the house. In a few months had been an hour,\n",
      "==================================================\n",
      "Mr. Darcy has inherited the estate from his aunt, so he must be very well; and the very often to be not blame on his coming to the first time; but he could not be his attentions to him, he might be in the other, if he had not been more than he was so many months\n"
     ]
    }
   ],
   "source": [
    "from generate_text import generate\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "text = generate(\n",
    "    model=model, prompt=\"Miss Bennet has inherited the estate from her aunt, so she must\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)\n",
    "    \n",
    "print(50*\"=\")\n",
    "    \n",
    "text = generate(\n",
    "    model=model, prompt=\"Mr. Darcy has inherited the estate from his aunt, so he must\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "714f6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good lady ought to be the rest of the evening, and their feelings which she was to the most natural.\n",
      "\"I do, my dear,\" said she, \"you should be done for my acquaintance.\"\n",
      "\"I am not seen him.\"\n",
      "Miss Bennet's\n",
      "==================================================\n",
      "A highly respectable man ought to be able to a little of his wife's affection for the rest of his present. He had been spent in the matter; and had been spared only one of his father, and the same time, he had been given to the most valuable voice, had\n"
     ]
    }
   ],
   "source": [
    "from generate_text import generate\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "text = generate(\n",
    "    model=model, prompt=\"A good lady ought to be\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=30\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)\n",
    "    \n",
    "print(50*\"=\")\n",
    "    \n",
    "text = generate(\n",
    "    model=model, prompt=\"A highly respectable man ought to be\",\n",
    "    max_new_tokens=50, context_size=GPT_CONFIG_124M['context_length'],\n",
    "    device=\"cpu\",\n",
    "    temperature=0.7,\n",
    "    top_k=30,\n",
    ")\n",
    "\n",
    "splitted = text.split(\"\\n\")\n",
    "for txt in splitted:\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dacdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"mps\":\n",
    "    clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a25f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
