{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0961a5-a839-4e6a-9272-60890bd10eea",
   "metadata": {},
   "source": [
    "# Sparse Autoencoders Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7f682-cf1a-4846-b22f-6da77b39d80f",
   "metadata": {},
   "source": [
    "This notebook evaluates the **Sparse Autoencoders (SAEs)** trained on different layers of the GPT & Prejudice model.  \n",
    "Each SAE captures interpretable latent features from the hidden representations of the transformer, helping us analyze what types of information each layer encodes.\n",
    "\n",
    "The goal of this evaluation is to:\n",
    "- load the trained GPT model and its layer-wise SAEs,\n",
    "- apply each SAE to hidden activations extracted from the model,\n",
    "- measure **reconstruction performance** (how well the SAE preserves the original activations),\n",
    "\n",
    "These evaluations form a baseline for later interpretability analyses, where the discovered sparse features are linked to human-understandable concepts (e.g., gender, emotion, class, or social role).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff8fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "\n",
    "from utils.model import load_GPT_model\n",
    "from utils.tokenization import text_to_token_ids\n",
    "from utils.embeddings import get_token_embeddings_from_sentence\n",
    "from sparse_auto_encoder import SparseAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a9490f-6d65-46b3-a733-01503d1e1830",
   "metadata": {},
   "source": [
    "### 1. Setup and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe351e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291556a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_GPT_model(path=\"model_896_14_8_256.pth\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6430cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899bdf1-cf80-4189-ab0c-efe6ff5bfd51",
   "metadata": {},
   "source": [
    "### 2. Load Sparse Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af40655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_1 = SparseAutoencoder(input_dim=896, hidden_dim=2688).to(device)\n",
    "sae_1.load_state_dict(torch.load(\"sae_models/sae_layer1.pth\", map_location=torch.device('cpu')))\n",
    "sae_1.eval();\n",
    "\n",
    "sae_2 = SparseAutoencoder(input_dim=896, hidden_dim=2688).to(device)\n",
    "sae_2.load_state_dict(torch.load(\"sae_models/sae_layer2.pth\", map_location=torch.device('cpu')))\n",
    "sae_2.eval();\n",
    "\n",
    "sae_3 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_3.load_state_dict(torch.load(\"sae_models/sae_layer3.pth\", map_location=torch.device('cpu')))\n",
    "sae_3.eval();\n",
    "\n",
    "sae_4 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_4.load_state_dict(torch.load(\"sae_models/sae_layer4.pth\", map_location=torch.device('cpu')))\n",
    "sae_4.eval();\n",
    "\n",
    "sae_5 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_5.load_state_dict(torch.load(\"sae_models/sae_layer5.pth\", map_location=torch.device('cpu')))\n",
    "sae_5.eval();\n",
    "\n",
    "sae_6 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_6.load_state_dict(torch.load(\"sae_models/sae_layer6.pth\", map_location=torch.device('cpu')))\n",
    "sae_6.eval();\n",
    "\n",
    "sae_7 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_7.load_state_dict(torch.load(\"sae_models/sae_layer7.pth\", map_location=torch.device('cpu')))\n",
    "sae_7.eval();\n",
    "\n",
    "sae_8 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_8.load_state_dict(torch.load(\"sae_models/sae_layer8.pth\", map_location=torch.device('cpu')))\n",
    "sae_8.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97450d93-3b0d-47f0-b7c3-29f077021a15",
   "metadata": {},
   "source": [
    "### 3. Layer-wise evaluation\n",
    "\n",
    "The helper function `evaluate_trained_sae()` runs a quantitative evaluation for a given SAE and GPT layer.  \n",
    "It performs the following steps:\n",
    "\n",
    "- Extracts hidden activations from the specified layer of the GPT model  \n",
    "- Passes them through the corresponding SAE for reconstruction  \n",
    "- Computes metrics such as:\n",
    "    - **Reconstruction MSE:** average squared error between original and reconstructed hidden states. Lower is better; captures information preserved in magnitude and direction.\n",
    "    - **Average cosine similarity:** angular alignment of original vs. reconstructed vectors. Values close to 1 indicate the SAE preserves representational direction.\n",
    "    - **Average L0 sparsity (active latents):** mean count of non-zero latent units per sample using a small threshold (|z| > 1e-5). Lower counts mean sparser, more selective features.\n",
    "    - **Cross-entropy and KL proxy:** a lightweight stress test: a randomly-initialized linear “next-token head” is applied to original vs. reconstructed states. The change in cross-entropy (using the original argmax as targets) and the **KL divergence** between the two logit distributions approximate how much the SAE’s reconstruction could perturb a downstream classifier head.\n",
    "  \n",
    "These metrics reveal how well each SAE captures the structure of its target layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfb698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_sae import evaluate_trained_sae\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630cb701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 0.128097\n",
      "Average Cosine Similarity: 0.704948\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 3.928008\n",
      "Cross-Entropy Loss (reconstructed): 4.322168\n",
      "KL Divergence (Reconstructed || Original): 0.022545\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_1, model, layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0848ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 0.200597\n",
      "Average Cosine Similarity: 0.851549\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 3.547400\n",
      "Cross-Entropy Loss (reconstructed): 3.929964\n",
      "KL Divergence (Reconstructed || Original): 0.034600\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_2, model, layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "681a8157-87d5-4bd3-add9-0fc17a1bc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 0.356255\n",
      "Average Cosine Similarity: 0.877400\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 3.329621\n",
      "Cross-Entropy Loss (reconstructed): 3.854797\n",
      "KL Divergence (Reconstructed || Original): 0.061886\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_3, model, layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15c3b1c-92cd-46c1-84bd-35adb0b6f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 0.505206\n",
      "Average Cosine Similarity: 0.896534\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 2.807891\n",
      "Cross-Entropy Loss (reconstructed): 3.289988\n",
      "KL Divergence (Reconstructed || Original): 0.088757\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_4, model, layer=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b8c752-f519-4b34-a0b9-2c0c34ea9aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 0.753457\n",
      "Average Cosine Similarity: 0.877576\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 2.580509\n",
      "Cross-Entropy Loss (reconstructed): 3.300773\n",
      "KL Divergence (Reconstructed || Original): 0.123802\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_5, model, layer=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c50f421-c583-44c7-9305-0b035981e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 1.077450\n",
      "Average Cosine Similarity: 0.855100\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 2.332970\n",
      "Cross-Entropy Loss (reconstructed): 3.226375\n",
      "KL Divergence (Reconstructed || Original): 0.186150\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_6, model, layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a17392-e388-4d4a-9425-942193dc06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 1.384787\n",
      "Average Cosine Similarity: 0.829606\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 2.303382\n",
      "Cross-Entropy Loss (reconstructed): 3.171908\n",
      "KL Divergence (Reconstructed || Original): 0.207862\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_7, model, layer=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e0beba-9293-415c-9fe3-6d76734ba2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after filtering: 2636\n",
      "Reconstruction MSE: 1.673100\n",
      "Average Cosine Similarity: 0.828214\n",
      "Average L0 Sparsity (active latents): 50.00\n",
      "Cross-Entropy Loss (original): 2.207709\n",
      "Cross-Entropy Loss (reconstructed): 3.158854\n",
      "KL Divergence (Reconstructed || Original): 0.265773\n"
     ]
    }
   ],
   "source": [
    "evaluate_trained_sae(sae_8, model, layer=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23536c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
