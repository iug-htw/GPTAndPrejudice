{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d797b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "from sparse_auto_encoder import SparseAutoencoder\n",
    "from utils.model import load_GPT_model\n",
    "from saes__extract_latent_activations import exract_latent_activations\n",
    "from saes__filter_selective_neurons import find_selective_neurons\n",
    "from saes__neuron_concept_assoc import calculate_neuron_to_concept_assoc\n",
    "from saes__top_texts_for_neuron import top_texts_for_neuron\n",
    "from saes__neuron_concept_mapping import build_neuron_concept_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff9a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624e271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_GPT_model(path=\"model_896_14_8_256.pth\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13960944",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_1 = SparseAutoencoder(input_dim=896, hidden_dim=2688).to(device)\n",
    "sae_1.load_state_dict(torch.load(\"sae_models/sae_layer1.pth\", map_location=torch.device('cpu')))\n",
    "sae_1.eval();\n",
    "\n",
    "sae_2 = SparseAutoencoder(input_dim=896, hidden_dim=2688).to(device)\n",
    "sae_2.load_state_dict(torch.load(\"sae_models/sae_layer2.pth\", map_location=torch.device('cpu')))\n",
    "sae_2.eval();\n",
    "\n",
    "sae_3 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_3.load_state_dict(torch.load(\"sae_models/sae_layer3.pth\", map_location=torch.device('cpu')))\n",
    "sae_3.eval();\n",
    "\n",
    "sae_4 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_4.load_state_dict(torch.load(\"sae_models/sae_layer4.pth\", map_location=torch.device('cpu')))\n",
    "sae_4.eval();\n",
    "\n",
    "sae_5 = SparseAutoencoder(input_dim=896, hidden_dim=3584).to(device)\n",
    "sae_5.load_state_dict(torch.load(\"sae_models/sae_layer5.pth\", map_location=torch.device('cpu')))\n",
    "sae_5.eval();\n",
    "\n",
    "sae_6 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_6.load_state_dict(torch.load(\"sae_models/sae_layer6.pth\", map_location=torch.device('cpu')))\n",
    "sae_6.eval();\n",
    "\n",
    "sae_7 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_7.load_state_dict(torch.load(\"sae_models/sae_layer7.pth\", map_location=torch.device('cpu')))\n",
    "sae_7.eval();\n",
    "\n",
    "sae_8 = SparseAutoencoder(input_dim=896, hidden_dim=4480).to(device)\n",
    "sae_8.load_state_dict(torch.load(\"sae_models/sae_layer8.pth\", map_location=torch.device('cpu')))\n",
    "sae_8.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sae_probing/latent_activations_l1.pt with latents shape torch.Size([665, 2688]) and 665 ids.\n",
      "✅ Saved sae_probing/latent_activations_l2.pt with latents shape torch.Size([665, 2688]) and 665 ids.\n",
      "✅ Saved sae_probing/latent_activations_l3.pt with latents shape torch.Size([665, 3584]) and 665 ids.\n",
      "✅ Saved sae_probing/latent_activations_l4.pt with latents shape torch.Size([665, 3584]) and 665 ids.\n",
      "✅ Saved sae_probing/latent_activations_l5.pt with latents shape torch.Size([665, 3584]) and 665 ids.\n",
      "✅ Saved sae_probing/latent_activations_l6.pt with latents shape torch.Size([665, 4480]) and 665 ids.\n"
     ]
    }
   ],
   "source": [
    "latents_l1 = exract_latent_activations(model, sae_1, layer=1)\n",
    "latents_l2 = exract_latent_activations(model, sae_2, layer=2)\n",
    "latents_l3 = exract_latent_activations(model, sae_3, layer=3)\n",
    "latents_l4 = exract_latent_activations(model, sae_4, layer=4)\n",
    "latents_l5 = exract_latent_activations(model, sae_5, layer=5)\n",
    "latents_l6 = exract_latent_activations(model, sae_6, layer=6)\n",
    "latents_l7 = exract_latent_activations(model, sae_7, layer=7)\n",
    "latents_l8 = exract_latent_activations(model, sae_8, layer=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b629ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_layer_neurons(layer, activation_threshold=5.0):\n",
    "    find_selective_neurons(layer=layer, activation_threshold=activation_threshold)\n",
    "    calculate_neuron_to_concept_assoc(layer=layer, threshold=activation_threshold);\n",
    "\n",
    "    mappings = build_neuron_concept_map(layer=layer)\n",
    "    print(f\"✅ Done for layer {layer}\")\n",
    "    print('='*10)\n",
    "    \n",
    "    return mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbb0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e2e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_layer_neurons(layer=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff86be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plot dual-themed neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0213a4a",
   "metadata": {},
   "source": [
    "Plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "color_map = {\n",
    "    \"female\": \"#FAD7AC\",\n",
    "    \"male\": \"#cc9290\",\n",
    "    \"marriage\": \"#ed76b3\",\n",
    "    \"love\": \"#CC0000\",\n",
    "    \"wealth\": \"#007FFF\",\n",
    "    \"emotion\": \"#9467bd\",\n",
    "    \"family\": \"#CC6600\",\n",
    "    \"duty\": \"#a4d9f2\",\n",
    "    \"scandal and reputation\": \"#B3B3B3\",\n",
    "    \"society\": \"#67AB9F\",\n",
    "    \"neutral\": \"#e5ced0\",\n",
    "    \"class\": \"#90ee90\"\n",
    "}\n",
    "\n",
    "def plot_dual_theme_graph_from_csv(\n",
    "    csv_path, *, color_map=color_map, ax=None, return_fig=False, seed=62,\n",
    "    layout=\"spring\", spread=1.8, layer=\"UNK\"\n",
    "):\n",
    "    \"\"\"Reads primary/secondary CSV and plots normalized dual-theme concept graph.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"primary_concept\" not in df.columns or \"secondary_concept\" not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'primary_concept' and 'secondary_concept' columns.\")\n",
    "    df = df.dropna(subset=[\"primary_concept\", \"secondary_concept\"])\n",
    "\n",
    "    # Build edge list (orderless)\n",
    "    edges = []\n",
    "    for _, row in df.iterrows():\n",
    "        a = str(row[\"primary_concept\"]).strip(\" ,\").lower()\n",
    "        b = str(row[\"secondary_concept\"]).strip(\" ,\").lower()\n",
    "        if a and b and a != \"unk\" and b != \"unk\":\n",
    "            edges.append((a, b))\n",
    "\n",
    "    if not edges:\n",
    "        fig, axp = plt.subplots(figsize=(6, 3))\n",
    "        axp.text(0.5, 0.5, \"No dual-theme data\", ha=\"center\", va=\"center\")\n",
    "        axp.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        return (fig, axp) if return_fig else None\n",
    "\n",
    "    G = nx.MultiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Create axes if needed\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        created_fig = True\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # ---- Layout ----\n",
    "    if layout == \"kk\":\n",
    "        pos = nx.kamada_kawai_layout(G)\n",
    "    else:\n",
    "        base_k = 0.75 / max(len(G.nodes), 1) ** 0.25\n",
    "        k = base_k * spread\n",
    "        pos = nx.spring_layout(G, k=k, seed=seed, iterations=200)\n",
    "\n",
    "    if spread > 1.0:\n",
    "        xs, ys = zip(*pos.values())\n",
    "        cx, cy = sum(xs)/len(xs), sum(ys)/len(ys)\n",
    "        for n in pos:\n",
    "            x, y = pos[n]\n",
    "            pos[n] = (cx + (x - cx) * 1.15, cy + (y - cy) * 1.15)\n",
    "\n",
    "    unique_nodes = list(G.nodes())\n",
    "    node_colors = [color_map.get(node, \"#cccccc\") for node in unique_nodes]\n",
    "\n",
    "    # ---- Edge normalization ----\n",
    "    edge_weights = {tuple(sorted((u, v))): G.number_of_edges(u, v) for u, v in G.edges()}\n",
    "    max_w = max(edge_weights.values())\n",
    "    # scale edge widths: 1 (minimum) → 10 (maximum)\n",
    "    norm_edges = {k: (0.5 + 19.5 * (w / max_w)) for k, w in edge_weights.items()}\n",
    "\n",
    "    # ---- Draw ----\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=8000, node_color=node_colors, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=14, font_weight=\"bold\", ax=ax)\n",
    "\n",
    "    drawn = set()\n",
    "    for (u, v), width in norm_edges.items():\n",
    "        if (u, v) in drawn:\n",
    "            continue\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=width, alpha=0.6, ax=ax)\n",
    "        drawn.add((u, v))\n",
    "\n",
    "    ax.set_title(f\"Layer {layer}\", fontsize=25)\n",
    "    ax.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if return_fig:\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302429cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l1.csv\", layout=\"kk\", layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l2.csv\", layout=\"kk\", layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l3.csv\", layout='kk', layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a234ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l4.csv\", layout='kk', layer=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l5.csv\", spread=100, layer=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7390494",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l6.csv\", spread=100, layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd05078",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l7.csv\", spread=100, layer=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3797c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_theme_graph_from_csv(\"sae_probing/neuron_concept_primary_secondary_l8.csv\", spread=100, layer=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97303d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"sae_probing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92398fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(base_dir, \"neuron_label_assoc_l*.csv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    # make sure each file has a 'layer' column\n",
    "    if \"layer\" not in df.columns:\n",
    "        # try to parse layer number from filename\n",
    "        layer_num = int(os.path.basename(f).split(\"_l\")[-1].split(\".\")[0])\n",
    "        df[\"layer\"] = layer_num\n",
    "    dfs.append(df)\n",
    "\n",
    "merged = pd.concat(dfs, ignore_index=True)\n",
    "out_path = os.path.join(base_dir, \"neuron_label_assoc_all_layers.csv\")\n",
    "merged.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"✅ Merged {len(files)} files into {out_path}, total rows: {len(merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(base_dir, \"neuron_concept_primary_secondary_l*.csv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    # make sure each file has a 'layer' column\n",
    "    if \"layer\" not in df.columns:\n",
    "        # try to parse layer number from filename\n",
    "        layer_num = int(os.path.basename(f).split(\"_l\")[-1].split(\".\")[0])\n",
    "        df[\"layer\"] = layer_num\n",
    "    dfs.append(df)\n",
    "\n",
    "merged = pd.concat(dfs, ignore_index=True)\n",
    "out_path = os.path.join(base_dir, \"neuron_concept_primary_secondary_all_layers.csv\")\n",
    "merged.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"✅ Merged {len(files)} files into {out_path}, total rows: {len(merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c02cb1-62ee-4c89-bba5-84efb4e4f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers_assoc = pd.read_csv(os.path.join(base_dir, \"neuron_label_assoc_all_layers.csv\"))\n",
    "all_layers_assoc = all_layers_assoc[all_layers_assoc[\"ΔP\"] >= 0]\n",
    "averages = (\n",
    "    all_layers_assoc\n",
    "    .drop(columns=[\"neuron\", \"concept\"])\n",
    "    .groupby(\"layer\").mean(numeric_only=True)\n",
    ")\n",
    "\n",
    "out_path = os.path.join(base_dir, \"analysis\", \"mean_assoc_metrics_all_layers.csv\")\n",
    "averages.to_csv(out_path)\n",
    "\n",
    "averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = all_layers_assoc[all_layers_assoc[\"AP\"] >= 0.5].sort_values(by='AP', ascending=False)\n",
    "top_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mappings = pd.read_csv(os.path.join(base_dir, \"neuron_concept_primary_secondary_all_layers.csv\"))\n",
    "# target (layer, neuron) pairs\n",
    "targets = list(zip(top_neurons[\"layer\"], top_neurons[\"neuron\"]))\n",
    "keys = pd.DataFrame(targets, columns=[\"layer\", \"neuron\"])\n",
    "\n",
    "filtered = all_mappings.merge(keys, on=[\"layer\", \"neuron\"], how=\"inner\").sort_values(by='primary_AP', ascending=False)\n",
    "# rows NOT in the targets:\n",
    "# dropped = df.merge(keys, on=[\"layer\",\"neuron\"], how=\"left\", indicator=True).query(\"_merge=='left_only'\").drop(columns=\"_merge\")\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"new results\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d215b-71f5-484f-90ee-8ef2ce95d30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
